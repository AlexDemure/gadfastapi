workdir = ""

exclude = [
    ".ci/__init__.py",
    ".ci/k8s/__init__.py",
    ".ci/k8s/helm/__init__.py",
    ".compose/__init__.py",
    "src/static/__init__.py",
]

folders = [
    ".ci",
    ".ci/k8s",
    ".ci/k8s/helm",
    ".compose",
    "src",
    "src/clients",
    "src/databases",
    "src/databases/postgres",
    "src/databases/postgres/crud",
    "src/databases/postgres/migrations",
    "src/databases/postgres/migrations/versions",
    "src/databases/postgres/tables",
    "src/domain",
    "src/domain/collections",
    "src/domain/collections/enums",
    "src/domain/collections/exceptions",
    "src/domain/models",
    "src/domain/repositories",
    "src/domain/services",
    "src/endpoints",
    "src/endpoints/http",
    "src/endpoints/http/const",
    "src/endpoints/http/const/errors",
    "src/endpoints/http/deps",
    "src/endpoints/http/openapi",
    "src/endpoints/http/systemapi",
    "src/framework",
    "src/static",
    "src/storages",
    "src/tools",
    "src/utils"
]

# Compose
[[files]]
path = ".compose/.env"
content = """
ENV=develop
POSTGRES_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/db
"""

[[files]]
path = ".compose/.env.example"
content = """
ENV=develop
POSTGRES_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/db
"""

[[files]]
path = ".compose/docker-compose.yaml"
content = """
version: "3.8"

volumes:
  .volumes:

services:
  postgres:
    image: postgres:16
    container_name: postgres
    hostname: postgres
    restart: always
    ports:
      - "5432:5432"
    volumes:
      - .volumes/pgdata:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_HOST: localhost
      POSTGRES_PORT: 5432
      POSTGRES_DB: db
    command: ["postgres", "-c", "log_statement=all"]
"""

# Root
[[files]]
path = ".gitignore"
content = """
.venv
.env
.mypy_cache
.ruff_cache
.pytest_cache
__pycache__
"""

[[files]]
path = ".env"
content = """
ENV=develop
POSTGRES_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/db
"""

[[files]]
path ="isort.cfg"
content = """
[settings]
line_length = 120
force_grid_wrap = 0
multi_line_output = 3
include_trailing_comma = true
force_single_line = true
"""

[[files]]
path ="alembic.ini"
content = """
[alembic]
script_location = src/databases/postgres/migrations

file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

prepend_sys_path = .

version_path_separator = os

sqlalchemy.url = driver://user:pass@localhost/dbname

[post_write_hooks]

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
"""

[[files]]
path ="cli.py"
content = """
import typer
import uvicorn

app = typer.Typer()

@app.command()
def run(workers: int = 1):
    uvicorn.run(
        "src.framework.application:app",
        port=8000,
        host="0.0.0.0",
        workers=workers,
        app_dir="src",
        log_config=None,
    )

if __name__ == "__main__":
    app()
"""

[[files]]
path ="Dockerfile"
content = """
FROM python:3.13-slim

WORKDIR /usr/app

RUN apt-get update && apt-get install -y \
    libpq-dev gcc python3-dev libffi-dev curl && \
    rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir uv

COPY pyproject.toml poetry.lock ./

RUN uv install --no-cache

COPY . .

EXPOSE 8000
"""

[[files]]
path ="ruff.toml"
content = """
exclude = [
    ".ruff_cache",
    ".venv",
    ".git",
    "__pycache__",
    ".pytest_cache",
    ".mypy_cache",
    "pyproject.toml"
]
include = ["*.py"]
respect-gitignore = true
show-fixes = true
line-length = 120
indent-width = 4
target-version = "py310"

[lint.extend-per-file-ignores]
"__init__.py" = ["F401", "F403"]

[lint.flake8-annotations]
suppress-none-returning = true

[lint.flake8-bandit]
check-typed-exception = true

[lint.flake8-pytest-style]
fixture-parentheses = true
mark-parentheses = true

[lint.flake8-quotes]
avoid-escape = true
docstring-quotes = "double"
inline-quotes = "double"
multiline-quotes = "double"

[lint.flake8-tidy-imports]
ban-relative-imports = "parents"

[format]
docstring-code-format = false
indent-style = "space"
line-ending = "auto"
quote-style = "double"
skip-magic-trailing-comma = false

[lint.isort]
case-sensitive = true
combine-as-imports = false
force-single-line = true
from-first = false
length-sort = true
lines-after-imports = 1
lines-between-types = 1
no-sections = false
order-by-type = true
split-on-trailing-comma = false
"""

[[files]]
path ="setup.cfg"
content = """
[mypy]
ignore_missing_imports = True
disable_error_code = var-annotated
exclude = .git,__pycache__,.pytest_cache,.mypy_cache,.venv/

# Disallow dynamic typing :: allow dynamic typing for now
disallow_any_unimported = True
disallow_any_generics = True
disallow_subclassing_any = True

# Untyped definitions and calls
disallow_untyped_calls = True
disallow_untyped_defs = True
disallow_incomplete_defs = True
disallow_untyped_decorators = True

# None and Optional handling
no_implicit_optional = True
strict_optional = True

# Configuring warnings
warn_redundant_casts = True
warn_unused_ignores = True
warn_no_return = True
warn_return_any = True
warn_unreachable = True

# Miscellaneous strictness flags
strict_equality = True
implicit_reexport = False

# Configuring error messages
show_error_context = True
show_column_numbers = True
show_error_codes = True
pretty = True

# Miscellaneous
warn_unused_configs = True
"""

[[files]]
path ="format.sh"
content = """
isort src/
ruff format src/ --no-cache
mypy src/
radon cc . -a -nc
"""

# Database
[[files]]
path ="src/databases/__init__.py"
content = """
from .exceptions import ObjectNotFoundError
from .orm import ORM
from .sessions import Session
"""

[[files]]
path ="src/databases/exceptions.py"
content = """
class ObjectNotFoundError(Exception): ...
"""

[[files]]
path ="src/databases/orm.py"
content = """
import typing

from src.databases import postgres

ORM = typing.TypeVar("ORM", bound=typing.Union[postgres.CRUD])
"""

[[files]]
path ="src/databases/sessions.py"
content = """
import typing

from src.databases import postgres

Session = typing.TypeVar("Session", bound=typing.Union[postgres.Session])
"""

[[files]]
path ="src/databases/postgres/__init__.py"
content = """
from .crud import CRUD as ORM
from .crud import *
from .setup import AsyncSession as Session  # type:ignore
from .setup import pgconnect
"""

[[files]]
path ="src/databases/postgres/setup.py"
content = """
import contextlib
import datetime
import decimal
import enum
import functools
import json

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.ext.asyncio import async_sessionmaker
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.ext.declarative import declarative_base

from src.framework import settings


class DatetimeAwareJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime.datetime):
            return obj.isoformat()
        elif isinstance(obj, datetime.date):
            return obj.isoformat()
        elif isinstance(obj, enum.Enum):
            return obj.value
        elif isinstance(obj, decimal.Decimal):
            return str(obj)
        try:
            return json.JSONEncoder.default(self, obj)
        except TypeError:
            return str(obj)


custom_serializer = functools.partial(json.dumps, cls=DatetimeAwareJSONEncoder, ensure_ascii=False)


_engine = create_async_engine(
    settings.POSTGRES_URL,
    echo=False,
    # echo_pool="debug",
    future=True,
    isolation_level="READ COMMITTED",  # Не изменять
    json_serializer=custom_serializer,
)

_sessionmaker = async_sessionmaker(_engine, expire_on_commit=False)

Table = declarative_base()


@contextlib.asynccontextmanager
async def _read() -> AsyncSession:
    async with _sessionmaker() as session:
        await session.connection(execution_options={"isolation_level": "AUTOCOMMIT"})
        yield session


@contextlib.asynccontextmanager
async def _write() -> AsyncSession:
    async with _sessionmaker() as session:
        try:
            async with session.begin():
                yield session
        except Exception as e:
            await session.rollback()
            raise e


@contextlib.asynccontextmanager
async def pgconnect(transaction: bool = False) -> AsyncSession:
    if transaction:
        async with _write() as session:
            yield session
    else:
        async with _read() as session:
            yield session
"""

[[files]]
path ="src/databases/postgres/crud/__init__.py"
content = """
from .base import CRUD
"""

[[files]]
path ="src/databases/postgres/crud/base.py"
content = """
import datetime

from sqlalchemy import BinaryExpression
from sqlalchemy import delete
from sqlalchemy import exists
from sqlalchemy import func
from sqlalchemy import select
from sqlalchemy import update
from sqlalchemy.exc import NoResultFound
from sqlalchemy.sql import Select

from src.databases.exceptions import ObjectNotFoundError
from src.databases.postgres.setup import AsyncSession
from src.databases.postgres.tables import Table


class CRUD:
    table: Table

    @classmethod
    def filters(cls, fields: dict) -> list[BinaryExpression]:
        expressions = []

        for key in fields.keys():
            if fields[key] is not None:
                if isinstance(fields[key], list):
                    expressions.append(getattr(cls.table, key).in_(fields[key]))
                elif isinstance(fields[key], datetime.date):
                    expressions.append(func.DATE(getattr(cls.table, key)) == fields[key])
                else:
                    expressions.append(getattr(cls.table, key) == fields[key])

        return expressions

    @classmethod
    async def one(cls, session: AsyncSession, **kwargs) -> Table:
        query = select(cls.table).where(*cls.filters(kwargs))
        return await fetchone(session, query)

    @classmethod
    async def relations(cls, session: AsyncSession, **kwargs) -> Table:
        raise NotImplementedError

    @classmethod
    async def paginated(
        cls,
        session: AsyncSession,
        filters: dict,
        sorting: dict,
        pagination: dict,
    ) -> tuple[list[Table], int]:
        raise NotImplementedError

    @classmethod
    async def all(cls, session: AsyncSession, **kwargs) -> list[Table]:
        query = select(cls.table).where(*cls.filters(kwargs))
        return await fetchall(session, query)

    @classmethod
    async def count(cls, session: AsyncSession, **kwargs) -> int:
        query = select(cls.table).where(*cls.filters(kwargs))
        return await count(session, query)

    @classmethod
    async def exists(cls, session: AsyncSession, **kwargs) -> bool:
        query = exists().where(*cls.filters(kwargs)).select()
        return (await session.execute(query)).scalar()

    @classmethod
    async def create(cls, session: AsyncSession, row: dict) -> Table:
        columns = {k: v for k, v in row.items() if getattr(cls.table, k, None) is not None}
        instance = cls.table(**columns)
        session.add(instance)
        await session.flush()
        return instance

    @classmethod
    async def update(cls, session: AsyncSession, id: str | int, **kwargs) -> None:
        columns = {k: v for k, v in kwargs.items() if getattr(cls.table, k, None) is not None}
        query = update(cls.table).where(cls.table.id == id).values(**columns)
        await session.execute(query)
        await session.flush()

    @classmethod
    async def delete(cls, session: AsyncSession, **kwargs) -> None:
        query = delete(cls.table).where(*cls.filters(kwargs))
        await session.execute(query)
        await session.flush()


async def fetchone(session: AsyncSession, query: Select) -> Table:
    try:
        return (await session.execute(query)).unique().scalars().one()
    except NoResultFound:
        raise ObjectNotFoundError


async def fetchall(session: AsyncSession, query: Select) -> list[Table]:
    return (await session.execute(query)).scalars().all()  # type:ignore


async def count(session: AsyncSession, query: Select) -> int:
    return (await session.execute(select(func.count()).select_from(query.subquery()))).scalars().one()
"""

[[files]]
path ="src/databases/postgres/migrations/env.py"
content = """
import asyncio
from logging.config import fileConfig

from alembic import context
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from sqlalchemy.ext.asyncio import AsyncEngine

from src.databases.postgres import tables  # noqa:F401
from src.databases.postgres.setup import Table
from src.framework import settings

config = context.config
config.set_main_option("sqlalchemy.url", settings.POSTGRES_URL)

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = Table.metadata

def run_migrations_offline() -> None:
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection):
    context.configure(connection=connection, target_metadata=target_metadata, compare_type=True)

    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online():
    connectable = AsyncEngine(
        engine_from_config(
            config.get_section(config.config_ini_section),
            prefix="sqlalchemy.",
            poolclass=pool.NullPool,
            future=True,
        )
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)


if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_migrations_online())
"""

[[files]]
path ="src/databases/postgres/migrations/script.py.mako"
content = '''
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}


revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
'''

[[files]]
path ="src/databases/postgres/tables/__init__.py"
content = """
from .base import Table
"""

[[files]]
path ="src/databases/postgres/tables/base.py"
content = """
import typing

from src.databases.postgres.setup import Table as _Table

Table = typing.TypeVar("Table", bound=_Table)
"""

# Domain
[[files]]
path ="src/domain/__init__.py"
content = """
from .collections import enums
from .collections import exceptions
"""

[[files]]
path ="src/domain/models/__init__.py"
content = """
from .base import Model
"""

[[files]]
path ="src/domain/models/base.py"
content = """
import pydantic

from src.databases.postgres.tables import Table


class Model(pydantic.BaseModel):
    model_config = pydantic.ConfigDict(from_attributes=True, extra="allow")

    @classmethod
    def to_dict(cls, table: Table) -> dict:
        return {k: v for k, v in table.__dict__.items() if not k.startswith("_")}

    @classmethod
    def to_model(cls, table: Table) -> "Model":
        model = Model.model_validate(cls.to_dict(table))

        for key, value in model.model_extra.items():
            if isinstance(value, Table.__bound__):
                setattr(model, key, cls.to_model(value))

        return model

    @classmethod
    def from_orm(cls, table: Table) -> "Model":
        model = cls.model_validate(cls.to_dict(table))

        for key, value in model.model_extra.items():
            if isinstance(value, Table.__bound__):
                setattr(model, key, cls.to_model(value))

        return model

    @classmethod
    def init(cls, *args, **kwargs) -> dict:
        raise NotImplementedError
"""

[[files]]
path ="src/domain/repositories/base.py"
content = """
import typing

from gadify import dates

from src.databases import ORM
from src.databases import ObjectNotFoundError
from src.databases import Session
from src.domain.models import Model


class Repository:
    orm: ORM
    model: Model
    error: Exception

    @classmethod
    async def one(cls, session: Session, **kwargs) -> "Repository.model":
        try:
            row = await cls.orm.one(session, **kwargs)
        except ObjectNotFoundError:
            raise cls.error

        return cls.model.from_orm(row)

    @classmethod
    async def relations(cls, session: Session, **kwargs) -> "Repository.model":
        try:
            row = await cls.orm.relations(session, **kwargs)
        except ObjectNotFoundError:
            raise cls.error

        return cls.model.from_orm(row)

    @classmethod
    async def paginated(
        cls,
        session: Session,
        filters: dict,
        sorting: dict,
        pagination: dict,
    ) -> tuple[list["Repository.model"], int]:
        rows, total = await cls.orm.paginated(session, filters, sorting, pagination)
        return [cls.model.from_orm(row) for row in rows], total

    @classmethod
    async def all(cls, session: Session, **kwargs) -> list["Repository.model"]:
        rows = await cls.orm.all(session, **kwargs)
        return [cls.model.from_orm(row) for row in rows]

    @classmethod
    async def count(cls, session: Session, **kwargs) -> int:
        return await cls.orm.count(session, **kwargs)

    @classmethod
    async def exists(cls, session: Session, **kwargs) -> bool:
        return await cls.orm.exists(session, **kwargs)

    @classmethod
    async def create(cls, session: Session, model: Model) -> "Repository.model":
        row = await cls.orm.create(session, row=model.dict())
        return cls.model.from_orm(row)

    @classmethod
    async def update(cls, session: Session, id: typing.Union[str, int], **kwargs) -> None:
        await cls.orm.update(session=session, id=id, updated_at=dates.now(), **kwargs)

    @classmethod
    async def delete(cls, session: Session, **kwargs) -> None:
        return await cls.orm.delete(session, **kwargs)
"""

[[files]]
path ="src/endpoints/http/schemas.py"
content = """
import typing

import pydantic

from src.domain import models


class ID(pydantic.BaseModel):
    id: typing.Union[int, str]

    @classmethod
    def serialize(cls, item: models.Model) -> typing.Self:
        return cls(id=item.id)


class Pagination(pydantic.BaseModel):
    page: pydantic.conint(gt=0, le=1000)
    size: pydantic.conint(gt=0, le=100)

    @property
    def deserialize(self) -> dict:
        return dict(limit=self.size, offset=(self.page - 1) * self.size if self.page > 0 else 0)


class Paginated(pydantic.BaseModel):
    total: int
    items: typing.List[typing.Any]
"""

[[files]]
path ="src/endpoints/http/openapi/__init__.py"
content = """
from src.tools.fastapi import APIRouter

router = APIRouter()
"""

[[files]]
path ="src/endpoints/http/systemapi/__init__.py"
content = """
from src.tools.fastapi import APIRouter

router = APIRouter()
"""

# Framework
[[files]]
path ="src/framework/settings.py"
content = """
import enum

import pydantic_settings


class Env(enum.StrEnum):
    develop = enum.auto()
    production = enum.auto()


class PostgresSettings(pydantic_settings.BaseSettings):
    POSTGRES_URL: str


configs = [
    PostgresSettings,
]


class Settings(*configs):  # type:ignore
    model_config = pydantic_settings.SettingsConfigDict(env_file=".env", case_sensitive=True, extra="ignore")

    ENV: Env


settings = Settings()
"""

[[files]]
path ="src/framework/logger.py"
content = """
import json
import logging
import sys

from gadlogger import Logger
from gadlogger import config

config.setup(Logger("root", logging.INFO, json, sys.stdout))

logger = logging.getLogger()
"""

[[files]]
path ="src/framework/application.py"
content = """
import contextlib

from fastapi import FastAPI
from fastapi import Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.openapi.docs import get_redoc_html
from fastapi.openapi.docs import get_swagger_ui_html
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from gadopenapi import OpenAPI
from gadopenapi.extensions.affix import affix
from gadopenapi.extensions.errors import APIError
from gadopenapi.extensions.operationid import use_route_as_operation_id

from src.endpoints.http import router


@contextlib.asynccontextmanager
async def lifespan(_: FastAPI):
    yield


app = FastAPI(
    lifespan=lifespan,
    docs_url=None,
    redoc_url=None,
    debug=True,
)


@app.get("/api/docs", include_in_schema=False)
async def swagger():
    return get_swagger_ui_html(openapi_url="/api/openapi.json", title=app.title)


@app.get("/api/redoc", include_in_schema=False)
async def redoc():
    return get_redoc_html(openapi_url="/api/openapi.json", title=app.title)


@app.get("/api/openapi.json", include_in_schema=False)
async def openapi():
    return OpenAPI(app, handlers=[affix, use_route_as_operation_id]).generate()


app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(router)

app.routing_exclude_paths = []  # src.tools.fastapi.routing.py

app.mount("/api/static", StaticFiles(directory="src/static"), name="static")


@app.exception_handler(APIError)
async def error_handler(_: Request, error: APIError) -> JSONResponse:
    return JSONResponse(status_code=error.status_code, content=error.to_dict())
"""

[[files]]
path ="src/framework/__init__.py"
content = """
from .logger import logger
from .settings import Env
from .settings import settings
"""

# Tools
[[files]]
path ="src/tools/fastapi/__init__.py"
content = """
from .routing import APIRouter
"""

[[files]]
path ="src/tools/fastapi/routing.py"
content = """
import contextlib
import functools
import json
import logging
import typing

from fastapi import APIRouter as _APIRouter
from fastapi import Request
from fastapi import status
from fastapi.exceptions import HTTPException
from fastapi.exceptions import ValidationException
from fastapi.routing import APIRoute as _APIRoute
from gadify import dates
from starlette.responses import Response

logger = logging.getLogger("fastapi.route")


class Logging:
    REQUEST_MAX_LENGTH = 16384
    RESPONSE_MAX_LENGTH = 65536

    def __init__(self, request: Request):
        self.context = self.init_context(request)

    @classmethod
    def init_context(cls, request: Request) -> dict:
        headers = dict(request.headers.items())

        hidden_headers = [
            "authorization",
        ]

        for key in hidden_headers:
            if headers.get(key, None):
                headers[key] = "*"

        return {
            "debug": request.app.debug,
            "service": request.app.title,
            "version": request.app.version,
            "http-version": request.scope.get("http_version", None),
            "ip": f"{request.client.host}:{request.client.port}",
            "method": request.method.upper(),
            "url": str(request.url),
            "headers": headers,
            "query": dict(request.query_params),
            "body": {},
            "response": {},
            "code": None,
            "started": dates.now(),
            "ended": None,
            "elapsed": None,
        }

    @property
    def endpoint(self) -> str:
        return f"{self.context['method']} {self.context['url']}"

    def timing(self):
        self.context["ended"] = dates.now()
        self.context["elapsed"] = (self.context["ended"] - self.context["started"]).total_seconds()

    def accepted(self) -> None:
        _logger = logger.warning if self.context.get("body") == "-" else logger.info
        _logger(f"Request accepted: {self.endpoint}", extra=self.context)

    def processed(self) -> None:
        _logger = logger.warning if self.context.get("response") == "-" else logger.info
        _logger(f"Request processed: {self.endpoint}", extra=self.context)

    def error(self) -> None:
        logger.error(f"Request error: {self.endpoint}", extra=self.context, exc_info=True)


class JSON:
    @classmethod
    def parseresponse(cls, response: Response):
        with contextlib.suppress(json.JSONDecodeError):
            return json.loads(response.body.decode("utf-8").replace("\n", ""))
        return response.body

    @classmethod
    async def parsebody(cls, request: Request):
        body = await request.body()
        with contextlib.suppress(json.JSONDecodeError):
            return json.loads(body.decode("utf-8").replace("\n", ""))
        return body


class APIRoute(_APIRoute):
    def get_route_handler(self) -> typing.Callable:
        original_route_handler = super().get_route_handler()

        async def custom_route_handler(request: Request) -> Response:
            if route := request.scope.get("route", None):  # noqa:SIM102
                if exclude_paths := getattr(request.app, "routing_exclude_paths", None):  # noqa:SIM102
                    if route.path_format in exclude_paths:
                        return await original_route_handler(request)

            log = Logging(request)

            if request.headers.get("Content-Type") == "application/json":
                with contextlib.suppress(ValueError):
                    log.context["body"] = (
                        await JSON.parsebody(request)
                        if int(request.headers.get("Content-Length", 0)) < log.REQUEST_MAX_LENGTH
                        else "-"
                    )

            log.accepted()

            try:
                response: Response = await original_route_handler(request)
                log.context["code"] = response.status_code
            except HTTPException as e:
                log.context["code"] = e.status_code
                log.context["response"] = e.detail
                log.timing()
                log.processed()
                raise e
            except ValidationException as e:
                log.context["code"] = status.HTTP_422_UNPROCESSABLE_ENTITY
                log.context["response"] = str(e)
                log.timing()
                log.processed()
                raise e
            except Exception as e:
                log.context["code"] = status.HTTP_500_INTERNAL_SERVER_ERROR
                log.timing()
                log.error()
                raise e

            if response.headers.get("Content-Type") == "application/json":
                log.context["response"] = (
                    JSON.parseresponse(response) if len(response.body) < log.RESPONSE_MAX_LENGTH else "-"
                )

            log.timing()
            log.processed()

            return response

        return custom_route_handler


APIRouter = functools.partial(_APIRouter, route_class=APIRoute)
"""

# Scripts
[[scripts]]
command = "isort ."
check = false

[[scripts]]
command = "ruff format . --no-cache"
check = false
